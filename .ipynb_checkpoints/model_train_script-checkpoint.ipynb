{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(backend=\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing required packages\n",
    "\n",
    "from my_model.Jagga import Jagga\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the learning rate, batch size and # of epoch to train\n",
    "\n",
    "learn_rate = 1e-4\n",
    "batch_size = 20\n",
    "epochs = 75\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train Images...\n",
      "14034\n",
      "14034\n"
     ]
    }
   ],
   "source": [
    "# loading the image dataset and initializing the list of data (images) and class images (labels)\n",
    "\n",
    "print(\"Loading Train Images...\")\n",
    "train_imagePaths = list(paths.list_images(\"D:/adity/Projects/image_classification/dataset/seg_train\"))\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for train_imagePath in train_imagePaths:\n",
    "    train_label = train_imagePath.split(os.path.sep)[-2]\n",
    "    train_image = cv2.imread(train_imagePath)\n",
    "    train_image = cv2.resize(train_image, (32, 32))\n",
    "    \n",
    "    # updating data and labels list respectively\n",
    "    train_data.append(train_image)\n",
    "    data.append(train_image)\n",
    "    train_labels.append(train_label)\n",
    "    labels.append(train_label)\n",
    "print(len(train_labels))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test Images...\n",
      "3000\n",
      "3000\n",
      "17034\n",
      "17034\n"
     ]
    }
   ],
   "source": [
    "# loading the image dataset and initializing the list of data (images) and class images (labels)\n",
    "# for testing images\n",
    "\n",
    "print(\"Loading Test Images...\")\n",
    "test_imagePaths = list(paths.list_images(\"D:/adity/Projects/image_classification/dataset/seg_test\"))\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for test_imagePath in test_imagePaths:\n",
    "    test_label = test_imagePath.split(os.path.sep)[-2]\n",
    "    test_image = cv2.imread(test_imagePath)\n",
    "    test_image = cv2.resize(test_image, (32, 32))\n",
    "    \n",
    "    # updating data and labels list respectively\n",
    "    test_data.append(test_image)\n",
    "    data.append(test_image)\n",
    "    test_labels.append(test_label)\n",
    "    labels.append(test_label)\n",
    "print(len(test_labels))\n",
    "print(len(test_data))\n",
    "print(len(labels))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert my dataset into numpy array and preprocess by scaling pixel intensities to range [0, 1]\n",
    "\n",
    "# train dataset\n",
    "train_data = np.array(train_data, dtype=\"float\") / 255.0\n",
    "\n",
    "# test dataset\n",
    "test_data = np.array(test_data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert my dataset into numpy array and preprocess by scaling pixel intensities to range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the train labels currently as strings, to integers and then one-hot encode them\n",
    "\n",
    "train_le = LabelEncoder()\n",
    "train_labels = train_le.fit_transform(train_labels)\n",
    "train_labels = np_utils.to_categorical(y=train_labels, num_classes=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the test labels currently as strings, to integers and then one-hot encode them\n",
    "\n",
    "test_le = LabelEncoder()\n",
    "test_labels = test_le.fit_transform(test_labels)\n",
    "test_labels = np_utils.to_categorical(y=test_labels, num_classes=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data labels currently as strings, to integers and then one-hot encode them\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = np_utils.to_categorical(y=labels, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning the dataset for training and testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "# aug will be used further to generate images from our data\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=36, zoom_range=0.2, width_shift_range=0.25, height_shift_range=0.25, shear_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model...\n"
     ]
    }
   ],
   "source": [
    "# Initializing the optimizer and compiling model\n",
    "\n",
    "print(\"Compiling Model...\")\n",
    "optm = Adam(learning_rate=learn_rate, decay=learn_rate/epochs)\n",
    "model = Jagga.build(width=32, height=32, depth=3, classes=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optm, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ModelX...\n"
     ]
    }
   ],
   "source": [
    "# Initializing the optimizer and compiling modelX\n",
    "\n",
    "print(\"Compiling ModelX...\")\n",
    "opt = Adam(learning_rate=learn_rate, decay=learn_rate/epochs)\n",
    "modelX = Jagga.build(width=32, height=32, depth=3, classes=len(train_le.classes_))\n",
    "modelX.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training networkX for : 75 epochs...\n",
      "Epoch 1/75\n",
      "701/701 [==============================] - 18s 26ms/step - loss: 0.5077 - accuracy: 0.8093 - val_loss: 0.3432 - val_accuracy: 0.8578\n",
      "Epoch 2/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.4078 - accuracy: 0.8360 - val_loss: 0.3248 - val_accuracy: 0.8701\n",
      "Epoch 3/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.3757 - accuracy: 0.8461 - val_loss: 0.3146 - val_accuracy: 0.8702\n",
      "Epoch 4/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.3554 - accuracy: 0.8529 - val_loss: 0.3064 - val_accuracy: 0.8739\n",
      "Epoch 5/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.3350 - accuracy: 0.8587 - val_loss: 0.3019 - val_accuracy: 0.8753\n",
      "Epoch 6/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.3249 - accuracy: 0.8618 - val_loss: 0.2802 - val_accuracy: 0.8836\n",
      "Epoch 7/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.3135 - accuracy: 0.8680 - val_loss: 0.2751 - val_accuracy: 0.8839\n",
      "Epoch 8/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.3081 - accuracy: 0.8694 - val_loss: 0.2627 - val_accuracy: 0.8867\n",
      "Epoch 9/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2986 - accuracy: 0.8728 - val_loss: 0.2618 - val_accuracy: 0.8897\n",
      "Epoch 10/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2941 - accuracy: 0.8741 - val_loss: 0.2494 - val_accuracy: 0.8948\n",
      "Epoch 11/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2910 - accuracy: 0.8769 - val_loss: 0.2532 - val_accuracy: 0.8947\n",
      "Epoch 12/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2875 - accuracy: 0.8777 - val_loss: 0.2278 - val_accuracy: 0.9045\n",
      "Epoch 13/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2843 - accuracy: 0.8798 - val_loss: 0.2443 - val_accuracy: 0.8964\n",
      "Epoch 14/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2771 - accuracy: 0.8814 - val_loss: 0.2525 - val_accuracy: 0.8963\n",
      "Epoch 15/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2762 - accuracy: 0.8834 - val_loss: 0.2350 - val_accuracy: 0.9003\n",
      "Epoch 16/75\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 0.2704 - accuracy: 0.8853 - val_loss: 0.2401 - val_accuracy: 0.8988\n",
      "Epoch 17/75\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.2692 - accuracy: 0.8863 - val_loss: 0.2281 - val_accuracy: 0.9012\n",
      "Epoch 18/75\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 0.2632 - accuracy: 0.8889 - val_loss: 0.2196 - val_accuracy: 0.9068\n",
      "Epoch 19/75\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 0.2644 - accuracy: 0.8884 - val_loss: 0.2150 - val_accuracy: 0.9100\n",
      "Epoch 20/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2640 - accuracy: 0.8900 - val_loss: 0.2309 - val_accuracy: 0.9046\n",
      "Epoch 21/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2607 - accuracy: 0.8900 - val_loss: 0.2261 - val_accuracy: 0.9058ac\n",
      "Epoch 22/75\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.2585 - accuracy: 0.8912 - val_loss: 0.2325 - val_accuracy: 0.9021\n",
      "Epoch 23/75\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.2593 - accuracy: 0.8913 - val_loss: 0.2345 - val_accuracy: 0.9054\n",
      "Epoch 24/75\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.2535 - accuracy: 0.8941 - val_loss: 0.2369 - val_accuracy: 0.9037\n",
      "Epoch 25/75\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.2567 - accuracy: 0.8925 - val_loss: 0.2117 - val_accuracy: 0.9135\n",
      "Epoch 26/75\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 0.2517 - accuracy: 0.8951 - val_loss: 0.2403 - val_accuracy: 0.9014\n",
      "Epoch 27/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2504 - accuracy: 0.8962 - val_loss: 0.2135 - val_accuracy: 0.9106\n",
      "Epoch 28/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2507 - accuracy: 0.8955 - val_loss: 0.2061 - val_accuracy: 0.9161\n",
      "Epoch 29/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2494 - accuracy: 0.8969 - val_loss: 0.2081 - val_accuracy: 0.9137\n",
      "Epoch 30/75\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 0.2483 - accuracy: 0.8977 - val_loss: 0.2400 - val_accuracy: 0.9022\n",
      "Epoch 31/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2432 - accuracy: 0.8980 - val_loss: 0.2079 - val_accuracy: 0.9153\n",
      "Epoch 32/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2451 - accuracy: 0.8983 - val_loss: 0.2194 - val_accuracy: 0.9095\n",
      "Epoch 33/75\n",
      "701/701 [==============================] - 13s 19ms/step - loss: 0.2428 - accuracy: 0.8993 - val_loss: 0.1956 - val_accuracy: 0.9209\n",
      "Epoch 34/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2437 - accuracy: 0.8992 - val_loss: 0.2196 - val_accuracy: 0.9116\n",
      "Epoch 35/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2410 - accuracy: 0.8995 - val_loss: 0.2115 - val_accuracy: 0.9142\n",
      "Epoch 36/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2374 - accuracy: 0.9028 - val_loss: 0.2145 - val_accuracy: 0.9127\n",
      "Epoch 37/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2393 - accuracy: 0.9008 - val_loss: 0.2074 - val_accuracy: 0.9171\n",
      "Epoch 38/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2377 - accuracy: 0.9017 - val_loss: 0.2037 - val_accuracy: 0.9171\n",
      "Epoch 39/75\n",
      "701/701 [==============================] - 12s 17ms/step - loss: 0.2355 - accuracy: 0.9034 - val_loss: 0.2139 - val_accuracy: 0.9128\n",
      "Epoch 40/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2332 - accuracy: 0.9048 - val_loss: 0.2069 - val_accuracy: 0.9159\n",
      "Epoch 41/75\n",
      "701/701 [==============================] - 13s 19ms/step - loss: 0.2347 - accuracy: 0.9022 - val_loss: 0.2036 - val_accuracy: 0.9144\n",
      "Epoch 42/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2323 - accuracy: 0.9051 - val_loss: 0.1924 - val_accuracy: 0.9217\n",
      "Epoch 43/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2319 - accuracy: 0.9054 - val_loss: 0.2139 - val_accuracy: 0.9125\n",
      "Epoch 44/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2311 - accuracy: 0.9055 - val_loss: 0.2030 - val_accuracy: 0.9179\n",
      "Epoch 45/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2278 - accuracy: 0.9062 - val_loss: 0.2041 - val_accuracy: 0.9166\n",
      "Epoch 46/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2303 - accuracy: 0.9069 - val_loss: 0.1963 - val_accuracy: 0.9214\n",
      "Epoch 47/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2305 - accuracy: 0.9057 - val_loss: 0.2157 - val_accuracy: 0.9127\n",
      "Epoch 48/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2251 - accuracy: 0.9087 - val_loss: 0.2102 - val_accuracy: 0.9129\n",
      "Epoch 49/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2258 - accuracy: 0.9075 - val_loss: 0.2121 - val_accuracy: 0.9132\n",
      "Epoch 50/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2227 - accuracy: 0.9093 - val_loss: 0.2034 - val_accuracy: 0.9178\n",
      "Epoch 51/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2247 - accuracy: 0.9084 - val_loss: 0.1971 - val_accuracy: 0.9205\n",
      "Epoch 52/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2260 - accuracy: 0.9074 - val_loss: 0.1998 - val_accuracy: 0.9194\n",
      "Epoch 53/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2234 - accuracy: 0.9097 - val_loss: 0.2094 - val_accuracy: 0.9148\n",
      "Epoch 54/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2255 - accuracy: 0.9080 - val_loss: 0.1904 - val_accuracy: 0.9227\n",
      "Epoch 55/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2211 - accuracy: 0.9099 - val_loss: 0.2055 - val_accuracy: 0.9164\n",
      "Epoch 56/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2214 - accuracy: 0.9098 - val_loss: 0.1817 - val_accuracy: 0.9292\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2191 - accuracy: 0.9111 - val_loss: 0.1953 - val_accuracy: 0.9221\n",
      "Epoch 58/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2214 - accuracy: 0.9094 - val_loss: 0.1931 - val_accuracy: 0.9221\n",
      "Epoch 59/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2211 - accuracy: 0.9104 - val_loss: 0.1885 - val_accuracy: 0.9241\n",
      "Epoch 60/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2210 - accuracy: 0.9112 - val_loss: 0.1900 - val_accuracy: 0.9234\n",
      "Epoch 61/75\n",
      "701/701 [==============================] - 13s 19ms/step - loss: 0.2218 - accuracy: 0.9091 - val_loss: 0.1976 - val_accuracy: 0.9196\n",
      "Epoch 62/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2190 - accuracy: 0.9102 - val_loss: 0.1935 - val_accuracy: 0.9238\n",
      "Epoch 63/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2175 - accuracy: 0.9106 - val_loss: 0.1945 - val_accuracy: 0.9219\n",
      "Epoch 64/75\n",
      "701/701 [==============================] - 13s 18ms/step - loss: 0.2186 - accuracy: 0.9108 - val_loss: 0.1950 - val_accuracy: 0.9212\n",
      "Epoch 65/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2161 - accuracy: 0.9131 - val_loss: 0.1919 - val_accuracy: 0.9243\n",
      "Epoch 66/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2172 - accuracy: 0.9123 - val_loss: 0.1773 - val_accuracy: 0.9301\n",
      "Epoch 67/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2167 - accuracy: 0.9121 - val_loss: 0.2085 - val_accuracy: 0.9183\n",
      "Epoch 68/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2184 - accuracy: 0.9113 - val_loss: 0.1956 - val_accuracy: 0.9217\n",
      "Epoch 69/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2138 - accuracy: 0.9130 - val_loss: 0.2034 - val_accuracy: 0.9194\n",
      "Epoch 70/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2155 - accuracy: 0.9118 - val_loss: 0.2000 - val_accuracy: 0.9212\n",
      "Epoch 71/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2131 - accuracy: 0.9136 - val_loss: 0.1731 - val_accuracy: 0.9323\n",
      "Epoch 72/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2140 - accuracy: 0.9141 - val_loss: 0.1952 - val_accuracy: 0.9222\n",
      "Epoch 73/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2152 - accuracy: 0.9127 - val_loss: 0.1883 - val_accuracy: 0.9256\n",
      "Epoch 74/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2145 - accuracy: 0.9139 - val_loss: 0.1916 - val_accuracy: 0.9239\n",
      "Epoch 75/75\n",
      "701/701 [==============================] - 12s 18ms/step - loss: 0.2113 - accuracy: 0.9138 - val_loss: 0.1816 - val_accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "# training the network\n",
    "\n",
    "print(\"Training networkX for : {} epochs...\".format(epochs))\n",
    "resX = modelX.fit_generator(aug.flow(train_data, train_labels, batch_size=batch_size), validation_data=(test_data, test_labels), steps_per_epoch=len(train_data)//batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   buildings       0.79      0.70      0.74       437\n",
      "      forest       0.74      0.98      0.84       474\n",
      "     glacier       0.70      0.85      0.77       553\n",
      "    mountain       0.82      0.73      0.77       525\n",
      "         sea       0.88      0.69      0.77       510\n",
      "      street       0.82      0.73      0.77       501\n",
      "\n",
      "    accuracy                           0.78      3000\n",
      "   macro avg       0.79      0.78      0.78      3000\n",
      "weighted avg       0.79      0.78      0.78      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Network...\")\n",
    "predictions = modelX.predict(test_data, batch_size=batch_size)\n",
    "print(classification_report(test_labels.argmax(axis=1), predictions.argmax(axis=1), target_names=test_le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am simply trying two ways to train my model and obtain a more efficient one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network for : 75 epochs...\n",
      "Epoch 1/75\n",
      "638/638 [==============================] - 18s 29ms/step - loss: 0.5125 - accuracy: 0.8112 - val_loss: 0.3181 - val_accuracy: 0.8690\n",
      "Epoch 2/75\n",
      "638/638 [==============================] - 11s 18ms/step - loss: 0.4110 - accuracy: 0.8364 - val_loss: 0.2975 - val_accuracy: 0.8761\n",
      "Epoch 3/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.3757 - accuracy: 0.8463 - val_loss: 0.2810 - val_accuracy: 0.8849\n",
      "Epoch 4/75\n",
      "638/638 [==============================] - 11s 18ms/step - loss: 0.3591 - accuracy: 0.8503 - val_loss: 0.2709 - val_accuracy: 0.8896\n",
      "Epoch 5/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.3399 - accuracy: 0.8576 - val_loss: 0.2646 - val_accuracy: 0.8909\n",
      "Epoch 6/75\n",
      "638/638 [==============================] - 11s 18ms/step - loss: 0.3293 - accuracy: 0.8616 - val_loss: 0.2602 - val_accuracy: 0.8928\n",
      "Epoch 7/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.3212 - accuracy: 0.8650 - val_loss: 0.2693 - val_accuracy: 0.8879\n",
      "Epoch 8/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.3128 - accuracy: 0.8671 - val_loss: 0.2487 - val_accuracy: 0.8970\n",
      "Epoch 9/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.3062 - accuracy: 0.8709 - val_loss: 0.2524 - val_accuracy: 0.8966\n",
      "Epoch 10/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2988 - accuracy: 0.8743 - val_loss: 0.2374 - val_accuracy: 0.9011\n",
      "Epoch 11/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2987 - accuracy: 0.8737 - val_loss: 0.2397 - val_accuracy: 0.8999\n",
      "Epoch 12/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2920 - accuracy: 0.8762 - val_loss: 0.2309 - val_accuracy: 0.9039\n",
      "Epoch 13/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2863 - accuracy: 0.8787 - val_loss: 0.2385 - val_accuracy: 0.8999\n",
      "Epoch 14/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2844 - accuracy: 0.8798 - val_loss: 0.2369 - val_accuracy: 0.9006\n",
      "Epoch 15/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2822 - accuracy: 0.8809 - val_loss: 0.2222 - val_accuracy: 0.9075\n",
      "Epoch 16/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2789 - accuracy: 0.8820 - val_loss: 0.2192 - val_accuracy: 0.9099\n",
      "Epoch 17/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2753 - accuracy: 0.8842 - val_loss: 0.2249 - val_accuracy: 0.9051\n",
      "Epoch 18/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2715 - accuracy: 0.8856 - val_loss: 0.2152 - val_accuracy: 0.9116\n",
      "Epoch 19/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2699 - accuracy: 0.8868 - val_loss: 0.2154 - val_accuracy: 0.9111\n",
      "Epoch 20/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2699 - accuracy: 0.8866 - val_loss: 0.2290 - val_accuracy: 0.9026\n",
      "Epoch 21/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2652 - accuracy: 0.8889 - val_loss: 0.2180 - val_accuracy: 0.9076\n",
      "Epoch 22/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2628 - accuracy: 0.8890 - val_loss: 0.2125 - val_accuracy: 0.9121\n",
      "Epoch 23/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2608 - accuracy: 0.8911 - val_loss: 0.2197 - val_accuracy: 0.9080\n",
      "Epoch 24/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2607 - accuracy: 0.8903 - val_loss: 0.2356 - val_accuracy: 0.9016\n",
      "Epoch 25/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2579 - accuracy: 0.8913 - val_loss: 0.2226 - val_accuracy: 0.9057\n",
      "Epoch 26/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2585 - accuracy: 0.8923 - val_loss: 0.2134 - val_accuracy: 0.9096\n",
      "Epoch 27/75\n",
      "638/638 [==============================] - 11s 18ms/step - loss: 0.2555 - accuracy: 0.8923 - val_loss: 0.2164 - val_accuracy: 0.9086\n",
      "Epoch 28/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2540 - accuracy: 0.8948 - val_loss: 0.2196 - val_accuracy: 0.9066\n",
      "Epoch 29/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2516 - accuracy: 0.8946 - val_loss: 0.2146 - val_accuracy: 0.9108\n",
      "Epoch 30/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2524 - accuracy: 0.8955 - val_loss: 0.1995 - val_accuracy: 0.9184\n",
      "Epoch 31/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2533 - accuracy: 0.8947 - val_loss: 0.2141 - val_accuracy: 0.9108\n",
      "Epoch 32/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2468 - accuracy: 0.8972 - val_loss: 0.2158 - val_accuracy: 0.9109\n",
      "Epoch 33/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2496 - accuracy: 0.8971 - val_loss: 0.2242 - val_accuracy: 0.9040\n",
      "Epoch 34/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2475 - accuracy: 0.8972 - val_loss: 0.2097 - val_accuracy: 0.9130\n",
      "Epoch 35/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2452 - accuracy: 0.8987 - val_loss: 0.2081 - val_accuracy: 0.9142\n",
      "Epoch 36/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2473 - accuracy: 0.8974 - val_loss: 0.1983 - val_accuracy: 0.9197\n",
      "Epoch 37/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2435 - accuracy: 0.8991 - val_loss: 0.2157 - val_accuracy: 0.9091\n",
      "Epoch 38/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2414 - accuracy: 0.9006 - val_loss: 0.2292 - val_accuracy: 0.9037\n",
      "Epoch 39/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2443 - accuracy: 0.8999 - val_loss: 0.2139 - val_accuracy: 0.9098\n",
      "Epoch 40/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2433 - accuracy: 0.8998 - val_loss: 0.1945 - val_accuracy: 0.9207\n",
      "Epoch 41/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2390 - accuracy: 0.9013 - val_loss: 0.1878 - val_accuracy: 0.9237\n",
      "Epoch 42/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2406 - accuracy: 0.9007 - val_loss: 0.1964 - val_accuracy: 0.9195\n",
      "Epoch 43/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2372 - accuracy: 0.9033 - val_loss: 0.2167 - val_accuracy: 0.9086\n",
      "Epoch 44/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2361 - accuracy: 0.9025 - val_loss: 0.2077 - val_accuracy: 0.9130\n",
      "Epoch 45/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2388 - accuracy: 0.9020 - val_loss: 0.1929 - val_accuracy: 0.9228\n",
      "Epoch 46/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2355 - accuracy: 0.9034 - val_loss: 0.1923 - val_accuracy: 0.9219\n",
      "Epoch 47/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2338 - accuracy: 0.9040 - val_loss: 0.2000 - val_accuracy: 0.9191\n",
      "Epoch 48/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2370 - accuracy: 0.9028 - val_loss: 0.1904 - val_accuracy: 0.9227\n",
      "Epoch 49/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2323 - accuracy: 0.9049 - val_loss: 0.2060 - val_accuracy: 0.9141\n",
      "Epoch 50/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2330 - accuracy: 0.9039 - val_loss: 0.2038 - val_accuracy: 0.9164\n",
      "Epoch 51/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2331 - accuracy: 0.9031 - val_loss: 0.2086 - val_accuracy: 0.9131\n",
      "Epoch 52/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2305 - accuracy: 0.9061 - val_loss: 0.1930 - val_accuracy: 0.9223\n",
      "Epoch 53/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2315 - accuracy: 0.9059 - val_loss: 0.1993 - val_accuracy: 0.9180\n",
      "Epoch 54/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2274 - accuracy: 0.9077 - val_loss: 0.1802 - val_accuracy: 0.9295\n",
      "Epoch 55/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2283 - accuracy: 0.9068 - val_loss: 0.1905 - val_accuracy: 0.9222\n",
      "Epoch 56/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2293 - accuracy: 0.9063 - val_loss: 0.1992 - val_accuracy: 0.9175\n",
      "Epoch 57/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2309 - accuracy: 0.9064 - val_loss: 0.2095 - val_accuracy: 0.9142\n",
      "Epoch 58/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2286 - accuracy: 0.9074 - val_loss: 0.1836 - val_accuracy: 0.9252\n",
      "Epoch 59/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2272 - accuracy: 0.9072 - val_loss: 0.1942 - val_accuracy: 0.9203\n",
      "Epoch 60/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2261 - accuracy: 0.9067 - val_loss: 0.1787 - val_accuracy: 0.9281\n",
      "Epoch 61/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2240 - accuracy: 0.9087 - val_loss: 0.1862 - val_accuracy: 0.9240\n",
      "Epoch 62/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2242 - accuracy: 0.9088 - val_loss: 0.1961 - val_accuracy: 0.9207\n",
      "Epoch 63/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2217 - accuracy: 0.9098 - val_loss: 0.2161 - val_accuracy: 0.9096\n",
      "Epoch 64/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2238 - accuracy: 0.9088 - val_loss: 0.1885 - val_accuracy: 0.9221\n",
      "Epoch 65/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2236 - accuracy: 0.9091 - val_loss: 0.1782 - val_accuracy: 0.9274\n",
      "Epoch 66/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2234 - accuracy: 0.9091 - val_loss: 0.1927 - val_accuracy: 0.9212\n",
      "Epoch 67/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2208 - accuracy: 0.9103 - val_loss: 0.1854 - val_accuracy: 0.9237\n",
      "Epoch 68/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2175 - accuracy: 0.9107 - val_loss: 0.1785 - val_accuracy: 0.9275\n",
      "Epoch 69/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2221 - accuracy: 0.9091 - val_loss: 0.1798 - val_accuracy: 0.9286\n",
      "Epoch 70/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2192 - accuracy: 0.9121 - val_loss: 0.2059 - val_accuracy: 0.9146\n",
      "Epoch 71/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2180 - accuracy: 0.9107 - val_loss: 0.1893 - val_accuracy: 0.9215\n",
      "Epoch 72/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2203 - accuracy: 0.9103 - val_loss: 0.1810 - val_accuracy: 0.9272\n",
      "Epoch 73/75\n",
      "638/638 [==============================] - 11s 17ms/step - loss: 0.2189 - accuracy: 0.9103 - val_loss: 0.1731 - val_accuracy: 0.9308\n",
      "Epoch 74/75\n",
      "638/638 [==============================] - 11s 18ms/step - loss: 0.2210 - accuracy: 0.9102 - val_loss: 0.1823 - val_accuracy: 0.9271\n",
      "Epoch 75/75\n",
      "638/638 [==============================] - 12s 18ms/step - loss: 0.2200 - accuracy: 0.9113 - val_loss: 0.1958 - val_accuracy: 0.9185\n"
     ]
    }
   ],
   "source": [
    "# training the network\n",
    "\n",
    "print(\"Training network for : {} epochs...\".format(epochs))\n",
    "res = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size), validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   buildings       0.85      0.56      0.68       658\n",
      "      forest       0.75      0.96      0.85       702\n",
      "     glacier       0.60      0.90      0.72       703\n",
      "    mountain       0.82      0.67      0.74       809\n",
      "         sea       0.87      0.63      0.73       661\n",
      "      street       0.75      0.76      0.76       726\n",
      "\n",
      "    accuracy                           0.75      4259\n",
      "   macro avg       0.78      0.75      0.75      4259\n",
      "weighted avg       0.77      0.75      0.75      4259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Network...\")\n",
    "predictions = model.predict(testX, batch_size=batch_size)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing NetworkX to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the Network i.e ModelX to Disk as it is more efficient\n",
    "\n",
    "print(\"Serializing NetworkX to disk\")\n",
    "modelX.save(\"jagga.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serializing Label Encoder to disk\n"
     ]
    }
   ],
   "source": [
    "# Saving the Label Encoder to disk as well\n",
    "\n",
    "print(\"Serializing Label Encoder to disk\")\n",
    "f = open(\"le.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(train_le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot the training loss and accuracy for both models\n",
    "# ModelX\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), resX.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), resX.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, epochs), resX.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, epochs), resX.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plotX.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epochs), res.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epochs), res.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, epochs), res.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, epochs), res.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
